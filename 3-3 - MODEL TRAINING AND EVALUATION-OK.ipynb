{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3924d7",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08d431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf501e5",
   "metadata": {},
   "source": [
    "# Load the ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b03c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = pd.read_csv('data_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ee039e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18108, 5001)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04372cbf",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3658e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = data_model[\"title_text\"]\n",
    "y = data_model[\"label\"]\n",
    "\n",
    "# Train Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Vectorizing the text\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "xv_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c922fb8",
   "metadata": {},
   "source": [
    "# Handle imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b1f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE + ENN to balance the training dataset\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "xv_train_resampled, y_train_resampled = smote_enn.fit_resample(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad89bd",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3ae41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      1367\n",
      "           1       0.98      0.86      0.92      2255\n",
      "\n",
      "    accuracy                           0.91      3622\n",
      "   macro avg       0.90      0.92      0.90      3622\n",
      "weighted avg       0.92      0.91      0.91      3622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xv_train_resampled, y_train_resampled)\n",
    "predictions_lr = lr.predict(xv_test)\n",
    "\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206c14dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Logistic Regression model performs well, achieving an overall accuracy of 91%. It shows high precision for class 1 \\n(Not A Fake News) but slightly lower recall (86%), meaning that while it correctly identifies most fake news, \\nit occasionally misclassifies true news as fake. Its precision and recall for class 0 (Fake News) are strong, making it \\nreliable for detecting fake news but with some room for improvement in handling true news.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The Logistic Regression model performs well, achieving an overall accuracy of 91%. It shows high precision for class 1 \n",
    "(Not A Fake News) but slightly lower recall (86%), meaning that while it correctly identifies most fake news, \n",
    "it occasionally misclassifies true news as fake. Its precision and recall for class 0 (Fake News) are strong, making it \n",
    "reliable for detecting fake news but with some room for improvement in handling true news.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba59cd",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2bc7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1367\n",
      "           1       0.98      0.92      0.95      2255\n",
      "\n",
      "    accuracy                           0.94      3622\n",
      "   macro avg       0.93      0.94      0.94      3622\n",
      "weighted avg       0.94      0.94      0.94      3622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(xv_train_resampled, y_train_resampled)\n",
    "predictions_rf = rf.predict(xv_test)\n",
    "\n",
    "print(\"Random Forest Classifier Performance:\")\n",
    "print(classification_report(y_test, predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226c4cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Random Forest model shows excellent performance with an accuracy of 94%. It balances precision and recall well across both \\nclasses, with precision and recall for class 1 (Not A Fake News) at 98% and 92%, respectively. It performs particularly well \\nin minimizing false negatives, making it very robust for this problem. This model edges out the Logistic Regression model due \\nto better performance on both classes.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The Random Forest model shows excellent performance with an accuracy of 94%. It balances precision and recall well across both \n",
    "classes, with precision and recall for class 1 (Not A Fake News) at 98% and 92%, respectively. It performs particularly well \n",
    "in minimizing false negatives, making it very robust for this problem. This model edges out the Logistic Regression model due \n",
    "to better performance on both classes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8485826",
   "metadata": {},
   "source": [
    "# Suport vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db88ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(xv_train_resampled, y_train_resampled)\n",
    "predictions_svm = svm.predict(xv_test)\n",
    "\n",
    "print(\"Support Vector Machine Performance:\")\n",
    "print(classification_report(y_test, predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3edd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The SVM model also delivers high performance, matching the Random Forest model in overall accuracy (94%). It demonstrates a \n",
    "strong balance between precision and recall, achieving 98% precision and 92% recall for class 1 (Not A Fake News), similar to \n",
    "the Random Forest. Its recall for class 0 (Fake News) is slightly higher, making it highly reliable in identifying fake news \n",
    "while maintaining accuracy in classifying true news.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5502e",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xv_train_resampled, y_train_resampled)\n",
    "predictions_dt = dt.predict(xv_test)\n",
    "\n",
    "print(\"Decision Tree Classifier Performance:\")\n",
    "print(classification_report(y_test, predictions_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ad716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Decision Tree model shows strong results, with an accuracy of 91%. It has a slight drop in precision for class 0 \n",
    "(Fake News) compared to other models (84%) but maintains a good balance overall, with 95% precision for class 1 \n",
    "(Not A Fake News). Although its performance is not as high as Random Forest or SVM, it is still a solid option, particularly \n",
    "when interpretability is a key concern due to the nature of decision trees.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc7fe1",
   "metadata": {},
   "source": [
    "# MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text cleaning function\n",
    "def text_cleaner(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove square brackets and their contents\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # Replace non-word characters with a space\n",
    "    text = re.sub(r\"\\W\", \" \", text)\n",
    "    # Remove URLs or website addresses\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # Remove newline characters\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    # Remove alphanumeric words containing digits\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    # Expand contractions (e.g., \"it's\" to \"it is\")\n",
    "    text = contractions.fix(text)\n",
    "    # Remove stopwords and perform lemmatization\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords_set]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Function to output the label based on prediction\n",
    "def output_label(prediction):\n",
    "    return \"Not A Fake News\" if prediction == 1 else \"Fake News\"\n",
    "\n",
    "# MODEL TESTING\n",
    "# Manual testing with rf classifier\n",
    "def rf_manual_testing(news, vectorization, rf):\n",
    "    # Prepare the new input for testing\n",
    "    testing_news = {\"text\": [news]}\n",
    "    new_def_test = pd.DataFrame(testing_news)\n",
    "    \n",
    "    # Apply preprocessing using text_cleaner\n",
    "    new_def_test[\"text\"] = new_def_test[\"text\"].apply(text_cleaner)\n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    \n",
    "    # Vectorize the new input\n",
    "    new_xv_test = vectorization.transform(new_x_test)\n",
    "    \n",
    "    # Get prediction from fr model\n",
    "    pred_RF = rf.predict(new_xv_test)\n",
    "    \n",
    "    # Print the prediction from the rf model\n",
    "    print(\"\\nRandom Forest Prediction: {}\".format(output_label(pred_RF[0])))\n",
    "\n",
    "# Input for testing\n",
    "news = str(input(\"Enter the news article text for testing: \"))\n",
    "rf_manual_testing(news, vectorization, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path\n",
    "model_path = r'C:\\Users\\elora\\Desktop\\IRONHACK\\PROJECTS\\FINAL PROJECT FAKE NEWS\\DATA AND NOTEBOOKS\\streamlit_app\\Models'\n",
    "\n",
    "# Save the trained rf model to a pickle file\n",
    "with open(f'{model_path}\\\\random_forest.pkl', 'wb') as model_file:\n",
    "    pickle.dump(rf, model_file)\n",
    "\n",
    "# Save the TF-IDF vectorizer to a pickle file\n",
    "with open(f'{model_path}\\\\tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorization, vectorizer_file)\n",
    "\n",
    "print(\"Random Forest model and vectorizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c09242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
